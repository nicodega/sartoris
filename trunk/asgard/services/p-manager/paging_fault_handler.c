/*
*	Process and Memory Manager Service
*
*	Copyright (C) 2002, 2003, 2004, 2005
*       
*	Santiago Bazerque 	sbazerque@gmail.com			
*	Nicolas de Galarreta	nicodega@gmail.com
*
*	
*	Redistribution and use in source and binary forms, with or without 
* 	modification, are permitted provided that conditions specified on 
*	the License file, located at the root project directory are met.
*
*	You should have received a copy of the License along with the code,
*	if not, it can be downloaded from our project site: sartoris.sourceforge.net,
*	or you can contact us directly at the email addresses provided above.
*
*
*/

#include <os/layout.h>
#include "pmanager_internals.h"
#include "page_list.h"

extern page_list free_pages;
extern int running;

struct taken_entries *taken;


int pm_handle_page_fault(int *thr_id, int internal_fault) 
{
	struct page_fault pf;
	void *page_addr;
	int task_id, thread_id;
	struct taken_entry tentry;
	int curr_thr;

	if(!internal_fault)
	{
		get_page_fault(&pf);

		task_id = pf.task_id; 
		thread_id = pf.thread_id;

		thread_info[thread_id].fault_entry = 0xFFFFFFFF;

		if(thr_id != NULL) *thr_id = thread_id;

		/* check if the same page is not being fetched by other thread of 
		the same task */
		curr_thr = task_info[thread_info[thread_id].task_id].first_thread;

		while(curr_thr != -1)
		{
			if( curr_thr != thread_id && thread_info[curr_thr].fault_next_thread == -1 && (thread_info[curr_thr].flags & THR_FLAG_PAGEFAULT) && PG_ADDRESS(thread_info[curr_thr].fault_address) == PG_ADDRESS(pf.linear) )
			{
				/* found last thread waiting for this page */
				thread_info[curr_thr].fault_next_thread = thread_id;	// set next thread as our current thread
				break;
			}

			curr_thr = thread_info[curr_thr].next_thread;
		}

		if(curr_thr != -1)
		{
			/* Page was being retrieved already for other thread! 
			block the thread.
			*/
			thread_info[thread_id].state = THR_BLOCKED;
			thread_info[thread_id].flags |= THR_FLAG_PAGEFAULT;
			thread_info[thread_id].fault_address = pf.linear;
			thread_info[thread_id].read_size = 0;
			thread_info[thread_id].page_perms = 0;
			thread_info[thread_id].page_displacement = 0;
			thread_info[thread_id].fault_next_thread = -1;
			thread_info[thread_id].swaptbl_next = -1;

			return 1;	// thread will remain on hold
		}		
	}
	else
	{
		/* Internal faults will be generated by the process manager itself when a 
		page table is fetched from swap file. */
		task_id = thread_info[*thr_id].task_id; 
		thread_id = *thr_id;

		thread_info[thread_id].fault_entry = 0xFFFFFFFF;

		pf.linear = thread_info[thread_id].fault_address;
		pf.task_id = task_id;
		pf.thread_id = thread_id;
	}

	/* Is page or page table on swap? */
	if(!(task_info[task_id].flags & TSK_FLAG_SYS_SERVICE) && check_page_swap(task_id, thread_id, (void*)PG_ADDRESS(pf.linear)) )
	{
		pman_print_and_stop("swapped");
		return 1;
	}

	unsigned int **base = (unsigned int **)PHYSICAL2LINEAR(PG_ADDRESS(task_info[task_id].page_dir));

	/* Lets see if the page table is present on the page directry and if not give it one */
	if(!(PG_PRESENT(base[PM_LINEAR_TO_DIR(pf.linear)])))
	{
		page_addr = pm_get_page();

		CREATE_TAKEN_TBL_ENTRY(&tentry, task_id, PM_LINEAR_TO_DIR( pf.linear ), ((task_info[task_id].flags & TSK_FLAG_SERVICE)? TAKEN_EFLAG_SERVICE : 0));
		pm_assign(page_addr, PMAN_TBL_ENTRY_NULL, &tentry );
		
		/* Insert a page for the page table */
		pm_page_in(task_id, pf.linear, (void *)page_addr, 1, PGATT_WRITE_ENA);

		task_info[task_id].page_count++;
	}

	unsigned int filepos, readsize;
	int page_displacement = 0;
	int perms = PGATT_WRITE_ENA;

	/* Must page be read from elf file? */
	if(!(task_info[task_id].flags & TSK_FLAG_SYS_SERVICE) && elf_filepos(task_id, pf.linear, &filepos, &readsize, &perms, &page_displacement))
	{
		thread_info[thread_id].state = THR_BLOCKED;
		thread_info[thread_id].flags |= THR_FLAG_PAGEFAULT;
		thread_info[thread_id].fault_address = pf.linear;
		thread_info[thread_id].read_size = readsize;
		thread_info[thread_id].page_perms = perms;
		thread_info[thread_id].page_displacement = page_displacement;
		thread_info[thread_id].fault_next_thread = -1;
		thread_info[thread_id].swaptbl_next = -1;

		/* Page will be granted before hand, so page stealing 
		thread won't attempt to take our page table */
		thread_info[thread_id].page_in_address = pm_get_page();

		/* IO lock page table, and set PF */
		struct taken_entry *ptentry = get_taken((void*)PG_ADDRESS(base[PM_LINEAR_TO_DIR(pf.linear)]));

		ptentry->data.b_ptbl.eflags |= TAKEN_EFLAG_IOLOCK | TAKEN_EFLAG_PF;

		CREATE_TAKEN_PG_ENTRY(&tentry, 0, PM_LINEAR_TO_TAB( thread_info[thread_id].fault_address ),  TAKEN_EFLAG_IOLOCK | ((task_info[task_id].flags & TSK_FLAG_SERVICE)? TAKEN_EFLAG_SERVICE : 0));
		pm_assign(thread_info[thread_id].page_in_address , PMAN_TBL_ENTRY_NULL, &tentry );

		pm_request_seek(thread_id, filepos);

		if(thread_info[curr_thr].swaptbl_next == -1)
		{
			/* Check if page fault is on a table currently being used by 
			other page fault IO. (this prevents removing IO lock from
			a table while pfaults are still being served) */

			/* Set swaptbl_next to the next thread waiting for a page on this table */
			int curr_thr = task_info[thread_info[thread_id].task_id].first_thread;

			while(curr_thr != -1)
			{
				if( curr_thr != thread_id && (thread_info[curr_thr].flags & THR_FLAG_PAGEFAULT) && thread_info[curr_thr].swaptbl_next == -1 && PM_LINEAR_TO_DIR(thread_info[curr_thr].fault_address) == PM_LINEAR_TO_DIR(PG_ADDRESS(pf.linear)) )
				{
					/* found last thread waiting for this page table */
					thread_info[curr_thr].swaptbl_next = thread_id;	// set next thread as our current thread
					break;
				}

				curr_thr = thread_info[curr_thr].next_thread;
			}
		}

		return 1;
	} 
	else 
	{
		/* set PF on page table */
		struct taken_entry *ptentry = get_taken((void*)PG_ADDRESS(base[PM_LINEAR_TO_DIR(pf.linear)]));

		ptentry->data.b_ptbl.eflags |= TAKEN_EFLAG_PF;

		/* Must page be assigned without initialization */
		page_addr = pm_get_page();

		CREATE_TAKEN_PG_ENTRY(&tentry, 0, PM_LINEAR_TO_TAB( pf.linear ), ((task_info[task_id].flags & TSK_FLAG_SERVICE)? TAKEN_EFLAG_SERVICE : 0));
		pm_assign(page_addr , CREATE_PMAN_TBL_ENTRY(task_id, PM_LINEAR_TO_DIR(pf.linear), 0 ), &tentry );

		pm_page_in(task_id, pf.linear, page_addr, 2, perms);

		task_info[task_id].page_count++;

		return 0;
	}
}






